$ train embedding, 2 pos_embed, loss_l2

Epoch 1, loss 2.58, acc 0.33 0.3681, time 33.80
Epoch 2, loss 2.19, acc 0.37 0.5510, time 41.73
Epoch 3, loss 1.63, acc 0.50 0.6459, time 38.26
Epoch 4, loss 1.24, acc 0.61 0.6901, time 37.89
Epoch 5, loss 0.96, acc 0.69 0.7118, time 38.53
Epoch 6, loss 0.81, acc 0.76 0.7188, time 38.59
Epoch 7, loss 0.39, acc 0.87 0.7287, time 38.05
Epoch 8, loss 0.46, acc 0.88 0.7372, time 39.25
Epoch 9, loss 0.35, acc 0.92 0.7427, time 37.55
Epoch 10, loss 0.36, acc 0.91 0.7431, time 38.95
Epoch 11, loss 0.26, acc 0.91 0.7460, time 39.52
Epoch 12, loss 0.18, acc 0.95 0.7490, time 38.70
Epoch 13, loss 0.13, acc 0.98 0.7527, time 38.97
Epoch 14, loss 0.16, acc 0.97 0.7479, time 37.40
Epoch 15, loss 0.12, acc 0.98 0.7534, time 37.10
Epoch 16, loss 0.15, acc 0.96 0.7541, time 39.05
Epoch 17, loss 0.10, acc 0.98 0.7541, time 37.66
Epoch 18, loss 0.06, acc 1.00 0.7571, time 40.29
Epoch 19, loss 0.07, acc 0.99 0.7549, time 40.35
Epoch 20, loss 0.07, acc 0.99 0.7571, time 41.44
Epoch 21, loss 0.05, acc 1.00 0.7567, time 42.53
Epoch 22, loss 0.07, acc 1.00 0.7593, time 39.82
Epoch 23, loss 0.03, acc 1.00 0.7593, time 37.62
Epoch 24, loss 0.04, acc 1.00 0.7600, time 38.72
Epoch 25, loss 0.03, acc 0.99 0.7600, time 37.43
Epoch 26, loss 0.03, acc 1.00 0.7541, time 38.77
Epoch 27, loss 0.04, acc 0.99 0.7552, time 37.12
Epoch 28, loss 0.02, acc 1.00 0.7575, time 39.08
Epoch 29, loss 0.02, acc 1.00 0.7549, time 37.40
Epoch 30, loss 0.02, acc 1.00 0.7575, time 38.86
Epoch 31, loss 0.01, acc 1.00 0.7575, time 38.73
Epoch 32, loss 0.02, acc 1.00 0.7541, time 37.46
Epoch 33, loss 0.01, acc 1.00 0.7549, time 37.79
Epoch 34, loss 0.01, acc 1.00 0.7552, time 38.31
Epoch 35, loss 0.01, acc 1.00 0.7519, time 37.23
Epoch 36, loss 0.01, acc 1.00 0.7560, time 37.16
Epoch 37, loss 0.01, acc 1.00 0.7530, time 38.54
Epoch 38, loss 0.02, acc 0.99 0.7497, time 38.78
Epoch 39, loss 0.01, acc 1.00 0.7571, time 37.02
Epoch 40, loss 0.01, acc 1.00 0.7560, time 38.82
Epoch 41, loss 0.01, acc 1.00 0.7567, time 38.52
Epoch 42, loss 0.01, acc 1.00 0.7567, time 37.36
Epoch 43, loss 0.01, acc 1.00 0.7523, time 37.26
Epoch 44, loss 0.01, acc 1.00 0.7560, time 37.15
Epoch 45, loss 0.01, acc 1.00 0.7567, time 38.87
Epoch 46, loss 0.01, acc 1.00 0.7571, time 40.94
Epoch 47, loss 0.01, acc 1.00 0.7586, time 41.67
Epoch 48, loss 0.00, acc 1.00 0.7571, time 37.74
Epoch 49, loss 0.00, acc 1.00 0.7571, time 38.79
Epoch 50, loss 0.00, acc 1.00 0.7556, time 37.29
Epoch 51, loss 0.00, acc 1.00 0.7575, time 39.01
Epoch 52, loss 0.01, acc 0.99 0.7567, time 37.60

0.7600


$ don't train embedding, 2 pos_embed, loss_l2


Epoch 1, loss 3.01, acc 0.18 0.3162, time 31.39
Epoch 2, loss 1.94, acc 0.39 0.4936, time 34.33
Epoch 3, loss 1.84, acc 0.41 0.5705, time 33.89
Epoch 4, loss 1.67, acc 0.45 0.6246, time 33.66
Epoch 5, loss 1.39, acc 0.54 0.6511, time 35.22
Epoch 6, loss 1.30, acc 0.58 0.6776, time 34.88
Epoch 7, loss 1.40, acc 0.47 0.6934, time 33.86
Epoch 8, loss 1.26, acc 0.59 0.7000, time 34.02
Epoch 9, loss 1.39, acc 0.53 0.7070, time 34.41
Epoch 10, loss 1.07, acc 0.60 0.7144, time 35.29
Epoch 11, loss 1.00, acc 0.70 0.7225, time 34.30
Epoch 12, loss 1.00, acc 0.63 0.7269, time 34.16
Epoch 13, loss 0.90, acc 0.68 0.7313, time 37.25
Epoch 14, loss 0.93, acc 0.66 0.7368, time 35.94
Epoch 15, loss 0.76, acc 0.74 0.7409, time 38.66
Epoch 16, loss 0.90, acc 0.74 0.7453, time 35.25
Epoch 17, loss 0.96, acc 0.64 0.7483, time 34.59
Epoch 18, loss 0.83, acc 0.74 0.7567, time 36.05
Epoch 19, loss 0.82, acc 0.76 0.7567, time 37.58
Epoch 20, loss 0.70, acc 0.80 0.7563, time 35.66
Epoch 21, loss 0.59, acc 0.76 0.7582, time 34.29
Epoch 22, loss 0.67, acc 0.77 0.7578, time 38.19
Epoch 23, loss 0.47, acc 0.86 0.7615, time 35.91
Epoch 24, loss 0.65, acc 0.80 0.7622, time 38.38
Epoch 25, loss 0.61, acc 0.74 0.7637, time 36.22
Epoch 26, loss 0.66, acc 0.83 0.7637, time 35.62
Epoch 27, loss 0.56, acc 0.82 0.7626, time 37.58
Epoch 28, loss 0.56, acc 0.82 0.7641, time 36.14
Epoch 29, loss 0.54, acc 0.82 0.7678, time 36.74
Epoch 30, loss 0.57, acc 0.78 0.7648, time 35.75
Epoch 31, loss 0.54, acc 0.84 0.7718, time 35.61
Epoch 32, loss 0.49, acc 0.83 0.7725, time 36.00
Epoch 33, loss 0.41, acc 0.85 0.7744, time 39.43
Epoch 34, loss 0.49, acc 0.80 0.7744, time 37.15
Epoch 35, loss 0.46, acc 0.84 0.7748, time 35.19
Epoch 36, loss 0.53, acc 0.82 0.7744, time 35.49
Epoch 37, loss 0.46, acc 0.83 0.7788, time 35.75
Epoch 38, loss 0.35, acc 0.88 0.7751, time 34.21
Epoch 39, loss 0.54, acc 0.83 0.7748, time 35.74
Epoch 40, loss 0.43, acc 0.87 0.7725, time 35.70
Epoch 41, loss 0.43, acc 0.83 0.7722, time 33.88
Epoch 42, loss 0.37, acc 0.86 0.7751, time 33.91
Epoch 43, loss 0.40, acc 0.85 0.7773, time 33.88
Epoch 44, loss 0.37, acc 0.87 0.7744, time 33.92
Epoch 45, loss 0.36, acc 0.87 0.7755, time 35.93
Epoch 46, loss 0.32, acc 0.91 0.7759, time 33.87
Epoch 47, loss 0.56, acc 0.80 0.7748, time 35.23
Epoch 48, loss 0.35, acc 0.88 0.7748, time 33.93
Epoch 49, loss 0.38, acc 0.89 0.7748, time 35.66
Epoch 50, loss 0.30, acc 0.93 0.7736, time 33.75
Done training, best_step: 2960, best_acc: 0.7788
duration: 0.49 hours


$ don't train embedding, 2 pos_embed, loss_l2


Epoch 1, loss 2.70, acc 0.26 0.3173, time 30.38
Epoch 2, loss 2.06, acc 0.44 0.4851, time 33.57
Epoch 3, loss 2.00, acc 0.37 0.5720, time 33.45
Epoch 4, loss 1.71, acc 0.48 0.6176, time 33.51
Epoch 5, loss 1.53, acc 0.52 0.6518, time 33.46
Epoch 6, loss 1.37, acc 0.58 0.6791, time 33.71
Epoch 7, loss 1.32, acc 0.52 0.6975, time 33.42
Epoch 8, loss 1.24, acc 0.64 0.7063, time 33.47
Epoch 9, loss 1.14, acc 0.64 0.7140, time 33.78
Epoch 10, loss 1.25, acc 0.54 0.7206, time 33.76
Epoch 11, loss 0.94, acc 0.66 0.7229, time 34.10
Epoch 12, loss 0.98, acc 0.68 0.7321, time 33.78
Epoch 13, loss 0.78, acc 0.75 0.7324, time 34.08
Epoch 14, loss 0.79, acc 0.71 0.7416, time 34.11
Epoch 15, loss 0.82, acc 0.72 0.7457, time 33.92
Epoch 16, loss 0.86, acc 0.68 0.7497, time 34.13
Epoch 17, loss 0.94, acc 0.70 0.7552, time 34.14
Epoch 18, loss 0.72, acc 0.77 0.7567, time 34.01
Epoch 19, loss 0.68, acc 0.76 0.7582, time 34.17
Epoch 20, loss 0.67, acc 0.75 0.7593, time 34.14
Epoch 21, loss 0.71, acc 0.78 0.7611, time 34.04
Epoch 22, loss 0.56, acc 0.83 0.7615, time 34.21
Epoch 23, loss 0.63, acc 0.77 0.7593, time 34.05
Epoch 24, loss 0.59, acc 0.83 0.7615, time 33.87
Epoch 25, loss 0.63, acc 0.76 0.7641, time 33.89
Epoch 26, loss 0.54, acc 0.82 0.7674, time 34.00
Epoch 27, loss 0.58, acc 0.78 0.7703, time 35.90
Epoch 28, loss 0.59, acc 0.81 0.7718, time 34.20
Epoch 29, loss 0.43, acc 0.88 0.7681, time 34.13
Epoch 30, loss 0.66, acc 0.77 0.7700, time 33.86
Epoch 31, loss 0.55, acc 0.83 0.7733, time 33.86
Epoch 32, loss 0.50, acc 0.85 0.7759, time 34.06
Epoch 33, loss 0.53, acc 0.86 0.7748, time 34.15
Epoch 34, loss 0.45, acc 0.88 0.7740, time 33.97
Epoch 35, loss 0.56, acc 0.83 0.7773, time 33.76
Epoch 36, loss 0.41, acc 0.86 0.7759, time 34.75
Epoch 37, loss 0.39, acc 0.81 0.7770, time 33.87
Epoch 38, loss 0.46, acc 0.82 0.7751, time 33.89
Epoch 39, loss 0.40, acc 0.85 0.7777, time 33.90
Epoch 40, loss 0.50, acc 0.81 0.7770, time 34.32
Epoch 41, loss 0.40, acc 0.86 0.7744, time 33.76
Epoch 42, loss 0.29, acc 0.92 0.7810, time 35.66
Epoch 43, loss 0.38, acc 0.86 0.7788, time 34.18
Epoch 44, loss 0.38, acc 0.84 0.7718, time 33.90
Epoch 45, loss 0.43, acc 0.87 0.7781, time 33.86
Epoch 46, loss 0.41, acc 0.84 0.7755, time 35.62
Epoch 47, loss 0.32, acc 0.90 0.7751, time 33.89
Epoch 48, loss 0.33, acc 0.90 0.7759, time 33.98
Epoch 49, loss 0.31, acc 0.91 0.7748, time 33.92
Epoch 50, loss 0.42, acc 0.79 0.7755, time 33.78
Epoch 51, loss 0.26, acc 0.91 0.7773, time 33.97
Epoch 52, loss 0.26, acc 0.92 0.7736, time 33.87
Epoch 53, loss 0.34, acc 0.87 0.7784, time 33.88
Epoch 54, loss 0.37, acc 0.89 0.7781, time 33.87
Epoch 55, loss 0.25, acc 0.95 0.7788, time 33.87
Epoch 56, loss 0.20, acc 0.93 0.7784, time 33.92
Epoch 57, loss 0.25, acc 0.94 0.7814, time 35.64
Epoch 58, loss 0.31, acc 0.90 0.7814, time 34.07
Epoch 59, loss 0.28, acc 0.89 0.7806, time 33.90
Epoch 60, loss 0.26, acc 0.91 0.7821, time 33.87
Epoch 61, loss 0.30, acc 0.91 0.7828, time 34.13
Epoch 62, loss 0.30, acc 0.90 0.7814, time 35.70
Epoch 63, loss 0.27, acc 0.91 0.7788, time 33.89
Epoch 64, loss 0.29, acc 0.91 0.7821, time 33.93
Epoch 65, loss 0.27, acc 0.91 0.7821, time 33.96
Epoch 66, loss 0.34, acc 0.87 0.7810, time 35.67
Epoch 67, loss 0.15, acc 0.97 0.7821, time 34.01
Epoch 68, loss 0.26, acc 0.92 0.7828, time 33.90
Epoch 69, loss 0.28, acc 0.89 0.7847, time 33.87
Epoch 70, loss 0.17, acc 0.93 0.7821, time 34.15
Epoch 71, loss 0.25, acc 0.91 0.7843, time 33.87
Epoch 72, loss 0.20, acc 0.93 0.7817, time 35.66
Epoch 73, loss 0.21, acc 0.92 0.7862, time 33.93
Epoch 74, loss 0.20, acc 0.92 0.7806, time 34.19
Epoch 75, loss 0.22, acc 0.93 0.7821, time 33.90
Epoch 76, loss 0.15, acc 0.95 0.7825, time 33.84
Epoch 77, loss 0.19, acc 0.91 0.7828, time 33.90
Epoch 78, loss 0.17, acc 0.94 0.7828, time 34.02
Epoch 79, loss 0.22, acc 0.94 0.7854, time 33.93
Epoch 80, loss 0.26, acc 0.91 0.7825, time 33.90
Epoch 81, loss 0.19, acc 0.96 0.7828, time 35.35
Epoch 82, loss 0.16, acc 0.94 0.7862, time 34.24
Epoch 83, loss 0.15, acc 0.98 0.7843, time 33.82
Epoch 84, loss 0.17, acc 0.93 0.7832, time 33.79
Epoch 85, loss 0.25, acc 0.90 0.7792, time 33.91
Epoch 86, loss 0.14, acc 0.94 0.7832, time 33.84
Epoch 87, loss 0.10, acc 0.99 0.7828, time 33.91
Epoch 88, loss 0.16, acc 0.96 0.7840, time 35.57
Epoch 89, loss 0.22, acc 0.95 0.7847, time 33.80
Epoch 90, loss 0.16, acc 0.95 0.7814, time 33.82
Epoch 91, loss 0.13, acc 0.96 0.7792, time 35.29
Epoch 92, loss 0.23, acc 0.92 0.7832, time 33.86
Epoch 93, loss 0.30, acc 0.89 0.7817, time 33.78
Epoch 94, loss 0.12, acc 0.96 0.7806, time 33.93
Epoch 95, loss 0.16, acc 0.96 0.7806, time 33.72
Epoch 96, loss 0.16, acc 0.94 0.7799, time 35.56
Epoch 97, loss 0.23, acc 0.92 0.7858, time 33.81
Epoch 98, loss 0.17, acc 0.96 0.7825, time 33.80
Epoch 99, loss 0.13, acc 0.96 0.7825, time 35.41
Epoch 100, loss 0.18, acc 0.94 0.7788, time 35.50
Epoch 101, loss 0.14, acc 0.94 0.7817, time 33.71
Epoch 102, loss 0.15, acc 0.95 0.7817, time 33.85
Epoch 103, loss 0.14, acc 0.93 0.7821, time 35.03
Epoch 104, loss 0.12, acc 0.96 0.7832, time 33.68
Epoch 105, loss 0.09, acc 0.98 0.7817, time 33.79
Epoch 106, loss 0.12, acc 0.96 0.7832, time 33.81
Epoch 107, loss 0.16, acc 0.95 0.7847, time 33.74
Epoch 108, loss 0.36, acc 0.87 0.7880, time 35.56
Epoch 109, loss 0.11, acc 0.95 0.7862, time 35.76
Epoch 110, loss 0.14, acc 0.94 0.7836, time 33.79
Epoch 111, loss 0.09, acc 0.97 0.7854, time 33.84
Epoch 112, loss 0.16, acc 0.95 0.7876, time 33.91
Epoch 113, loss 0.13, acc 0.95 0.7803, time 33.73
Epoch 114, loss 0.12, acc 0.96 0.7814, time 33.84
Epoch 115, loss 0.16, acc 0.92 0.7814, time 33.81
Epoch 116, loss 0.14, acc 0.95 0.7817, time 33.84
Epoch 117, loss 0.17, acc 0.96 0.7814, time 35.54
Epoch 118, loss 0.09, acc 0.98 0.7799, time 33.85
Epoch 119, loss 0.12, acc 0.98 0.7770, time 33.74
Epoch 120, loss 0.27, acc 0.92 0.7847, time 33.82
Epoch 121, loss 0.15, acc 0.94 0.7836, time 33.85
Epoch 122, loss 0.19, acc 0.93 0.7876, time 33.80
Epoch 123, loss 0.21, acc 0.90 0.7817, time 33.78
Epoch 124, loss 0.08, acc 0.98 0.7828, time 33.68
Epoch 125, loss 0.15, acc 0.96 0.7854, time 35.61
Epoch 126, loss 0.12, acc 0.97 0.7880, time 33.79
Epoch 127, loss 0.15, acc 0.93 0.7865, time 33.81
Epoch 128, loss 0.13, acc 0.96 0.7840, time 33.72
Epoch 129, loss 0.18, acc 0.95 0.7851, time 33.74
Epoch 130, loss 0.09, acc 0.97 0.7803, time 33.80
Epoch 131, loss 0.08, acc 0.97 0.7817, time 33.80
Epoch 132, loss 0.07, acc 0.98 0.7862, time 33.84
Epoch 133, loss 0.20, acc 0.93 0.7851, time 33.76
Epoch 134, loss 0.12, acc 0.97 0.7858, time 35.64
Epoch 135, loss 0.11, acc 0.98 0.7854, time 33.73
Epoch 136, loss 0.13, acc 0.95 0.7832, time 35.55
Epoch 137, loss 0.16, acc 0.96 0.7851, time 33.79
Epoch 138, loss 0.16, acc 0.96 0.7828, time 33.82
Epoch 139, loss 0.12, acc 0.96 0.7828, time 33.85
Epoch 140, loss 0.12, acc 0.96 0.7847, time 33.91
Epoch 141, loss 0.11, acc 0.96 0.7828, time 33.85
Epoch 142, loss 0.17, acc 0.95 0.7825, time 33.74
Epoch 143, loss 0.11, acc 0.96 0.7836, time 33.68
Epoch 144, loss 0.09, acc 0.96 0.7840, time 33.81
Epoch 145, loss 0.15, acc 0.94 0.7810, time 35.44
Epoch 146, loss 0.11, acc 0.96 0.7836, time 33.76
Epoch 147, loss 0.15, acc 0.95 0.7869, time 34.01
Epoch 148, loss 0.15, acc 0.93 0.7858, time 33.80
Epoch 149, loss 0.12, acc 0.96 0.7836, time 35.31
Epoch 150, loss 0.07, acc 0.97 0.7817, time 34.08
Epoch 151, loss 0.09, acc 0.96 0.7832, time 33.81
Epoch 152, loss 0.11, acc 0.98 0.7862, time 33.77
Epoch 153, loss 0.11, acc 0.97 0.7865, time 33.73
Epoch 154, loss 0.12, acc 0.96 0.7858, time 35.57
Epoch 155, loss 0.16, acc 0.94 0.7825, time 33.73
Epoch 156, loss 0.08, acc 0.99 0.7806, time 33.73
Epoch 157, loss 0.13, acc 0.96 0.7832, time 33.89
Epoch 158, loss 0.14, acc 0.90 0.7862, time 33.77
Epoch 159, loss 0.13, acc 0.98 0.7821, time 33.79
Epoch 160, loss 0.11, acc 0.95 0.7836, time 35.62
Epoch 161, loss 0.12, acc 0.97 0.7843, time 33.78
Epoch 162, loss 0.09, acc 0.96 0.7840, time 33.72
Epoch 163, loss 0.08, acc 0.99 0.7836, time 33.87
Epoch 164, loss 0.08, acc 0.97 0.7847, time 35.55
Epoch 165, loss 0.13, acc 0.96 0.7825, time 33.73
Epoch 166, loss 0.05, acc 0.98 0.7840, time 33.71
Epoch 167, loss 0.08, acc 0.97 0.7865, time 33.77
Epoch 168, loss 0.08, acc 0.97 0.7828, time 33.82
Epoch 169, loss 0.06, acc 0.98 0.7854, time 33.79
Epoch 170, loss 0.16, acc 0.95 0.7825, time 33.81
Epoch 171, loss 0.08, acc 0.98 0.7828, time 33.94
Epoch 172, loss 0.11, acc 0.96 0.7836, time 35.58
Epoch 173, loss 0.10, acc 0.97 0.7840, time 33.91
Epoch 174, loss 0.10, acc 0.96 0.7843, time 33.83
Epoch 175, loss 0.10, acc 0.96 0.7843, time 33.77
Epoch 176, loss 0.07, acc 0.99 0.7873, time 33.87
Epoch 177, loss 0.11, acc 0.97 0.7843, time 35.57
Epoch 178, loss 0.13, acc 0.94 0.7843, time 33.88
Epoch 179, loss 0.15, acc 0.96 0.7832, time 33.70
Epoch 180, loss 0.13, acc 0.96 0.7847, time 33.84
Epoch 181, loss 0.04, acc 1.00 0.7814, time 35.55
Epoch 182, loss 0.14, acc 0.95 0.7781, time 33.80
Epoch 183, loss 0.16, acc 0.95 0.7821, time 33.71
Epoch 184, loss 0.09, acc 0.97 0.7814, time 33.78
Epoch 185, loss 0.13, acc 0.94 0.7836, time 33.79
Epoch 186, loss 0.05, acc 0.99 0.7806, time 33.75
Epoch 187, loss 0.14, acc 0.96 0.7806, time 35.62
Epoch 188, loss 0.11, acc 0.95 0.7847, time 33.78
Epoch 189, loss 0.10, acc 0.97 0.7806, time 33.92
Epoch 190, loss 0.16, acc 0.93 0.7828, time 35.53
Epoch 191, loss 0.12, acc 0.95 0.7862, time 33.80
Epoch 192, loss 0.09, acc 0.96 0.7862, time 33.91
Epoch 193, loss 0.05, acc 0.98 0.7869, time 33.74
Epoch 194, loss 0.04, acc 0.98 0.7851, time 35.62
Epoch 195, loss 0.17, acc 0.96 0.7843, time 35.61
Epoch 196, loss 0.07, acc 0.98 0.7858, time 33.95
Epoch 197, loss 0.12, acc 0.98 0.7873, time 33.71
Epoch 198, loss 0.11, acc 0.97 0.7840, time 33.81
Epoch 199, loss 0.07, acc 0.97 0.7843, time 34.07
Epoch 200, loss 0.12, acc 0.97 0.7814, time 33.80
Done training, best_step: 8640, best_acc: 0.7880
duration: 1.90 hours



<<< (2*9+1)-WAY EVALUATION (USING DIRECTIONALITY)>>>:

Confusion matrix:
        C-E1 C-E2 C-W1 C-W2 C-C1 C-C2 E-D1 E-O1 E-O2 I-A1 I-A2 M-C1 M-C2 M-T1 M-T2 P-P1 P-P2  _O_ *ED2 <-- classified as
      +-----------------------------------------------------------------------------------------------+ -SUM- skip ACTUAL
 C-E1 | 125    1    0    0    0    0    0    0    1    0    1    0    0    0    0    0    0    6    0 |  134    0  134
 C-E2 |   2  175    0    0    0    0    0    1    0    1    0    0    0    0    0    4    0   10    0 |  193    0  193
 C-W1 |   0    0  138   10    0    0    2    0    0    0    1    0    2    0    0    0    2   18    0 |  173    0  173
 C-W2 |   1    0    4  104    0    0    0    0    0    0    2    0    4    1    0    0    3   12    0 |  131    0  131
 C-C1 |   0    0    2    0  132    3    7    0    1    0    0    0    0    0    0    0    0   21    1 |  167    0  167
 C-C2 |   0    0    1    1    2   30    0    0    0    0    0    0    0    0    0    0    0    2    0 |   36    0   36
 E-D1 |   0    0    1    1   11    0  268    4    1    0    1    1    0    0    0    1    1   33    0 |  323    0  323
 E-O1 |   0    9    0    1    2    0    0  187    0    0    1    1    1    2    1    6    1   28    0 |  240    0  240
 E-O2 |   1    0    0    1    0    1    0    0   40    0    0    0    1    0    0    0    0    2    0 |   46    0   46
 I-A1 |   0    0    4    0    0    0    0    0    0   12    0    0    1    0    0    2    0    5    0 |   24    0   24
 I-A2 |   0    0    1    6    0    0    0    1    0    1  107    1    0    0    0    0   10   17    0 |  144    0  144
 M-C1 |   0    0    1    0    0    0    0    0    0    0    0   24    0    0    0    0    0    5    0 |   30    0   30
 M-C2 |   0    0    2    2    0    0    0    0    0    0    1    0  175    1    0    0    1   19    0 |  201    0  201
 M-T1 |   2    0    0    4    0    1    1    1    0    0    2    0    1  195    1    1    2   36    0 |  247    0  247
 M-T2 |   0    0    0    2    1    0    0    2    0    0    1    1    0    3   42    0    3    7    0 |   62    0   62
 P-P1 |   0    3    0    0    0    0    0    5    0    2    0    0    0    0    0   88    0   12    0 |  110    0  110
 P-P2 |   0    0    0    3    0    0    1    0    1    0    2    0    1    0    1    1   91   13    0 |  114    0  114
  _O_ |   3    6    8   15    5    4   12   10    3    6   15    4   15    8    6    5    9  208    0 |  342    0  342
      +-----------------------------------------------------------------------------------------------+
 -SUM-  134  194  162  150  153   39  291  211   47   22  134   32  201  210   51  108  123  454    1   2717    0 2717

Coverage = 2717/2717 = 100.00%
Accuracy (calculated for the above confusion matrix) = 2141/2717 = 78.80%
Accuracy (considering all skipped examples as Wrong) = 2141/2717 = 78.80%
Accuracy (considering all skipped examples as Other) = 2141/2717 = 78.80%

Results for the individual relations:
      Cause-Effect(e1,e2) :    P =  125/ 134 =  93.28%     R =  125/ 134 =  93.28%     F1 =  93.28%
      Cause-Effect(e2,e1) :    P =  175/ 194 =  90.21%     R =  175/ 193 =  90.67%     F1 =  90.44%
   Component-Whole(e1,e2) :    P =  138/ 162 =  85.19%     R =  138/ 173 =  79.77%     F1 =  82.39%
   Component-Whole(e2,e1) :    P =  104/ 150 =  69.33%     R =  104/ 131 =  79.39%     F1 =  74.02%
 Content-Container(e1,e2) :    P =  132/ 153 =  86.27%     R =  132/ 167 =  79.04%     F1 =  82.50%
 Content-Container(e2,e1) :    P =   30/  39 =  76.92%     R =   30/  36 =  83.33%     F1 =  80.00%
Entity-Destination(e1,e2) :    P =  268/ 291 =  92.10%     R =  268/ 323 =  82.97%     F1 =  87.30%
     Entity-Origin(e1,e2) :    P =  187/ 211 =  88.63%     R =  187/ 240 =  77.92%     F1 =  82.93%
     Entity-Origin(e2,e1) :    P =   40/  47 =  85.11%     R =   40/  46 =  86.96%     F1 =  86.02%
 Instrument-Agency(e1,e2) :    P =   12/  22 =  54.55%     R =   12/  24 =  50.00%     F1 =  52.17%
 Instrument-Agency(e2,e1) :    P =  107/ 134 =  79.85%     R =  107/ 144 =  74.31%     F1 =  76.98%
 Member-Collection(e1,e2) :    P =   24/  32 =  75.00%     R =   24/  30 =  80.00%     F1 =  77.42%
 Member-Collection(e2,e1) :    P =  175/ 201 =  87.06%     R =  175/ 201 =  87.06%     F1 =  87.06%
     Message-Topic(e1,e2) :    P =  195/ 210 =  92.86%     R =  195/ 247 =  78.95%     F1 =  85.34%
     Message-Topic(e2,e1) :    P =   42/  51 =  82.35%     R =   42/  62 =  67.74%     F1 =  74.34%
  Product-Producer(e1,e2) :    P =   88/ 108 =  81.48%     R =   88/ 110 =  80.00%     F1 =  80.73%
  Product-Producer(e2,e1) :    P =   91/ 123 =  73.98%     R =   91/ 114 =  79.82%     F1 =  76.79%
                   _Other :    P =  208/ 454 =  45.81%     R =  208/ 342 =  60.82%     F1 =  52.26%

Micro-averaged result (excluding Other):
P = 1933/2262 =  85.46%     R = 1933/2375 =  81.39%     F1 =  83.37%

MACRO-averaged result (excluding Other):
P =  82.01%	R =  79.48%	F1 =  80.57%



<<< (9+1)-WAY EVALUATION IGNORING DIRECTIONALITY >>>:

Confusion matrix:
         C-E  C-W  C-C  E-D  E-O  I-A  M-C  M-T  P-P  _O_ <-- classified as
      +--------------------------------------------------+ -SUM- skip ACTUAL
  C-E | 303    0    0    0    2    2    0    0    4   16 |  327    0  327
  C-W |   1  256    0    2    0    3    6    1    5   30 |  304    0  304
  C-C |   0    4  167    8    1    0    0    0    0   23 |  203    0  203
  E-D |   0    2   11  268    5    1    1    0    2   33 |  323    0  323
  E-O |  10    2    3    0  227    1    3    3    7   30 |  286    0  286
  I-A |   0   11    0    0    1  120    2    0   12   22 |  168    0  168
  M-C |   0    5    0    0    0    1  199    1    1   24 |  231    0  231
  M-T |   2    6    2    1    3    3    2  241    6   43 |  309    0  309
  P-P |   3    3    0    1    6    4    1    1  180   25 |  224    0  224
  _O_ |   9   23    9   12   13   21   19   14   14  208 |  342    0  342
      +--------------------------------------------------+
 -SUM-  328  312  192  292  258  156  233  261  231  454   2717    0 2717

Coverage = 2717/2717 = 100.00%
Accuracy (calculated for the above confusion matrix) = 2169/2717 = 79.83%
Accuracy (considering all skipped examples as Wrong) = 2169/2717 = 79.83%
Accuracy (considering all skipped examples as Other) = 2169/2717 = 79.83%

Results for the individual relations:
             Cause-Effect :    P =  303/ 328 =  92.38%     R =  303/ 327 =  92.66%     F1 =  92.52%
          Component-Whole :    P =  256/ 312 =  82.05%     R =  256/ 304 =  84.21%     F1 =  83.12%
        Content-Container :    P =  167/ 192 =  86.98%     R =  167/ 203 =  82.27%     F1 =  84.56%
       Entity-Destination :    P =  268/ 292 =  91.78%     R =  268/ 323 =  82.97%     F1 =  87.15%
            Entity-Origin :    P =  227/ 258 =  87.98%     R =  227/ 286 =  79.37%     F1 =  83.46%
        Instrument-Agency :    P =  120/ 156 =  76.92%     R =  120/ 168 =  71.43%     F1 =  74.07%
        Member-Collection :    P =  199/ 233 =  85.41%     R =  199/ 231 =  86.15%     F1 =  85.78%
            Message-Topic :    P =  241/ 261 =  92.34%     R =  241/ 309 =  77.99%     F1 =  84.56%
         Product-Producer :    P =  180/ 231 =  77.92%     R =  180/ 224 =  80.36%     F1 =  79.12%
                   _Other :    P =  208/ 454 =  45.81%     R =  208/ 342 =  60.82%     F1 =  52.26%

Micro-averaged result (excluding Other):
P = 1961/2263 =  86.65%     R = 1961/2375 =  82.57%     F1 =  84.56%

MACRO-averaged result (excluding Other):
P =  85.97%	R =  81.93%	F1 =  83.82%



<<< (9+1)-WAY EVALUATION TAKING DIRECTIONALITY INTO ACCOUNT -- OFFICIAL >>>:

Confusion matrix:
         C-E  C-W  C-C  E-D  E-O  I-A  M-C  M-T  P-P  _O_ <-- classified as
      +--------------------------------------------------+ -SUM- xDIRx skip  ACTUAL
  C-E | 300    0    0    0    2    2    0    0    4   16 |  324     3     0    327
  C-W |   1  242    0    2    0    3    6    1    5   30 |  290    14     0    304
  C-C |   0    4  162    8    1    0    0    0    0   23 |  198     5     0    203
  E-D |   0    2   11  268    5    1    1    0    2   33 |  323     0     0    323
  E-O |  10    2    3    0  227    1    3    3    7   30 |  286     0     0    286
  I-A |   0   11    0    0    1  119    2    0   12   22 |  167     1     0    168
  M-C |   0    5    0    0    0    1  199    1    1   24 |  231     0     0    231
  M-T |   2    6    2    1    3    3    2  237    6   43 |  305     4     0    309
  P-P |   3    3    0    1    6    4    1    1  179   25 |  223     1     0    224
  _O_ |   9   23    9   12   13   21   19   14   14  208 |  342     0     0    342
      +--------------------------------------------------+
 -SUM-  325  298  187  292  258  155  233  257  230  454   2689    28     0   2717

Coverage = 2717/2717 = 100.00%
Accuracy (calculated for the above confusion matrix) = 2141/2717 = 78.80%
Accuracy (considering all skipped examples as Wrong) = 2141/2717 = 78.80%
Accuracy (considering all skipped examples as Other) = 2141/2717 = 78.80%

Results for the individual relations:
             Cause-Effect :    P =  300/( 325 +   3) =  91.46%     R =  300/ 327 =  91.74%     F1 =  91.60%
          Component-Whole :    P =  242/( 298 +  14) =  77.56%     R =  242/ 304 =  79.61%     F1 =  78.57%
        Content-Container :    P =  162/( 187 +   5) =  84.38%     R =  162/ 203 =  79.80%     F1 =  82.03%
       Entity-Destination :    P =  268/( 292 +   0) =  91.78%     R =  268/ 323 =  82.97%     F1 =  87.15%
            Entity-Origin :    P =  227/( 258 +   0) =  87.98%     R =  227/ 286 =  79.37%     F1 =  83.46%
        Instrument-Agency :    P =  119/( 155 +   1) =  76.28%     R =  119/ 168 =  70.83%     F1 =  73.46%
        Member-Collection :    P =  199/( 233 +   0) =  85.41%     R =  199/ 231 =  86.15%     F1 =  85.78%
            Message-Topic :    P =  237/( 257 +   4) =  90.80%     R =  237/ 309 =  76.70%     F1 =  83.16%
         Product-Producer :    P =  179/( 230 +   1) =  77.49%     R =  179/ 224 =  79.91%     F1 =  78.68%
                   _Other :    P =  208/( 454 +   0) =  45.81%     R =  208/ 342 =  60.82%     F1 =  52.26%

Micro-averaged result (excluding Other):
P = 1933/2263 =  85.42%     R = 1933/2375 =  81.39%     F1 =  83.35%

MACRO-averaged result (excluding Other):
P =  84.79%	R =  80.79%	F1 =  82.65%



<<< The official score is (9+1)-way evaluation with directionality taken into account: macro-averaged F1 = 82.65% >>>
